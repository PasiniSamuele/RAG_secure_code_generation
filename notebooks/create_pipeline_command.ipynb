{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\\n    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\\n    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\\n\\n    #evaluation parameters\\n    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\\n    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\\n    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\\n    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\\n    parser.add_argument('--top_n_metric', type=str, default='accuracy', help='metric used to select the best experiments in the run')\\n    parser.add_argument('--top_n', type=int, action='append', help='top_n value to be considered for the top_n_metric, you can append more than one')\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation parameters\n",
    "'''\n",
    "    parser.add_argument('--model_name', type=str, default='gpt-3.5-turbo', help='name of the model')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help='model temperature')\n",
    "\n",
    "    #task parameters\n",
    "    parser.add_argument('--task', type=str, default='data/tasks/detect_xss_simple_prompt.txt', help='input task')\n",
    "    parser.add_argument('--template', type=str, default='data/templates/complete_function.yaml', help='template for the prompt')\n",
    "    parser.add_argument('--prompt_parameters', type=str, default='data/prompt_parameters/empty.yaml', help='parameters to format the prompt template')\n",
    "    parser.add_argument('--generation_mode', type=str, default='one_shot', help='Generation mode: one_shot, few_shot, rag or react')\n",
    "\n",
    "    #output\n",
    "    parser.add_argument('--experiments_folder', type=str, default='experiments', help='experiments folder')\n",
    "    parser.add_argument('--experiments', type=int, default=25, help= 'number of experiments to run')\n",
    "    parser.add_argument('--parameters_file_name', type=str, default='parameters.json', help='name of the parameters file')\n",
    "    parser.add_argument('--input_prompt_file_name', type=str, default='prompt.txt', help='name of the input prompt file')\n",
    "\n",
    "    #hf paramerters \n",
    "    parser.add_argument('--hf_max_new_tokens', type=int, default=400, help='max new tokens for hf model')\n",
    "    parser.add_argument('--hf_load_in_4bit', type=bool, default=True, help='load in 4 bit for hf model (qlora quantization)')\n",
    "\n",
    "    #reproducibility\n",
    "    parser.add_argument('--seed', type=int, default=None, help='seed for reproducibility')\n",
    "\n",
    "    #few shot parameters\n",
    "    parser.add_argument('--example_template', type=str, default='data/example_templates/detect_xss_simple', help='template for the examples')\n",
    "    parser.add_argument('--examples_per_class', type=int, default=2, help='number of examples for each class')\n",
    "    parser.add_argument('--examples_file', type=str, default='data/train.csv', help='file containing the examples')\n",
    "    parser.add_argument('--examples_payload_column', type=str, default='Payloads', help='column containing the payloads')\n",
    "    parser.add_argument('--examples_label_column', type=str, default='Class', help='column containing the labels')\n",
    "    parser.add_argument('--example_positive_label', type=str, default='Malicious', help='Label for positive examples')\n",
    "    parser.add_argument('--example_negative_label', type=str, default='Benign', help='Label for negative examples')\n",
    "\n",
    "    #rag parameters\n",
    "    parser.add_argument('--rag_template_file', type=str, default='data/rag_templates/basic_rag_suffix.txt', help='template for the prompt with RAG')\n",
    "    parser.add_argument('--rag_source', type=str, default='data/papers', help='folder with papers or url of a webpage')\n",
    "    parser.add_argument('--db_persist_path', type=str, default='data/db/chroma', help='path to the db')\n",
    "    parser.add_argument('--chunk_size', type=int, default=1000, help='chunk size')\n",
    "    parser.add_argument('--chunk_overlap', type=int, default=200, help='chunk overlap')\n",
    "\n",
    "'''\n",
    "\n",
    "#evaluation parameters\n",
    "'''\n",
    "    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\n",
    "    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\n",
    "    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\n",
    "\n",
    "    #evaluation parameters\n",
    "    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\n",
    "    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\n",
    "    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\n",
    "    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\n",
    "    parser.add_argument('--top_n_metric', type=str, default='accuracy', help='metric used to select the best experiments in the run')\n",
    "    parser.add_argument('--top_n', type=int, action='append', help='top_n value to be considered for the top_n_metric, you can append more than one')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"src/generation_test_pipeline.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_filter_cheat_sheet = \"https://cheatsheetseries.owasp.org/cheatsheets/XSS_Filter_Evasion_Cheat_Sheet.html\"\n",
    "url_testing = \"https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model_name\" : \"gpt-4-1106-preview\", # gpt-4-1106-preview  gpt-3.5-turbo-0613\n",
    "    \"temperature\" : 1.0,\n",
    "    \"task\" : \"data/tasks/detect_xss_simple_prompt.txt\",\n",
    "    \"template\" : \"data/templates/complete_function_readable.yaml\",\n",
    "    \"prompt_parameters\" : \"data/prompt_parameters/empty.yaml\",\n",
    "    \"generation_mode\" : \"rag\",\n",
    "    \"experiments_folder\" : \"experiments\",\n",
    "    \"experiments\" : 50,\n",
    "    \"parameters_file_name\" : \"parameters.json\",\n",
    "    \"input_prompt_file_name\" : \"prompt.txt\",\n",
    "    \"hf_max_new_tokens\" : 400,\n",
    "    \"hf_load_in_4bit\" : True,\n",
    "    \"seed\" : 156,\n",
    "    \"example_template\" : \"data/example_templates/detect_xss_simple_prompt.txt\",\n",
    "    \"examples_per_class\" : 0,\n",
    "    \"examples_file\" : \"data/train.csv\",\n",
    "    \"examples_payload_column\" : \"Payloads\",\n",
    "    \"examples_label_column\" : \"Class\",\n",
    "    \"example_positive_label\" : \"Malicious\",\n",
    "    \"example_negative_label\" : \"Benign\",\n",
    "    \"rag_template_file\" : \"data/rag_templates/basic_rag_suffix.txt\",\n",
    "    \"rag_source\" : url_testing,         #\"data/papers\",\n",
    "    \"db_persist_path\" : \"data/db/chroma_web_test\",\n",
    "    \"chunk_size\" : 1000,\n",
    "    \"chunk_overlap\" : 200,\n",
    "    \n",
    "\n",
    "\n",
    "    \"run\" : None,\n",
    "    \"data\" : \"data/val.csv\",\n",
    "    \"function_name\" : \"detect_xss\",\n",
    "    \"isolated_execution\" : None,\n",
    "    \"summarize_results\" : True,\n",
    "    \"result_file_name\" : \"results.json\",\n",
    "    \"create_confusion_matrix\" : True,\n",
    "    \"top_n_metric\" : \"accuracy\",\n",
    "    \"top_n\" : [1, 3, 5, 10, 15]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/generation_test_pipeline.py --model_name gpt-3.5-turbo-0613 --temperature 1.0 --task data/tasks/detect_xss_simple_prompt.txt --template data/templates/complete_function_readable.yaml --prompt_parameters data/prompt_parameters/empty.yaml --generation_mode rag --experiments_folder experiments --experiments 50 --parameters_file_name parameters.json --input_prompt_file_name prompt.txt --hf_max_new_tokens 400 --hf_load_in_4bit True --seed 156 --example_template data/example_templates/detect_xss_simple_prompt.txt --examples_per_class 0 --examples_file data/train.csv --examples_payload_column Payloads --examples_label_column Class --example_positive_label Malicious --example_negative_label Benign --rag_template_file data/rag_templates/basic_rag_suffix.txt --rag_source https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting --db_persist_path data/db/chroma_web_test --chunk_size 1000 --chunk_overlap 200 --data data/val.csv --function_name detect_xss --summarize_results True --result_file_name results.json --create_confusion_matrix True --top_n_metric accuracy --top_n 1 --top_n 3 --top_n 5 --top_n 10 --top_n 15 \n"
     ]
    }
   ],
   "source": [
    "command = f\"python {script} \"\n",
    "for k,v in params.items():\n",
    "    if v is not None and k != \"top_n\":\n",
    "        command += f\"--{k} {v} \"\n",
    "    elif k == \"top_n\":\n",
    "        for n in v:\n",
    "            command += f\"--{k} {n} \"\n",
    "\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
