{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\\n    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\\n    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\\n\\n    #evaluation parameters\\n    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\\n    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\\n    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\\n    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\\n\\n\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation parameters\n",
    "'''\n",
    "    parser.add_argument('--model_name', type=str, default='gpt-3.5-turbo', help='name of the model')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help='model temperature')\n",
    "\n",
    "    #task parameters\n",
    "    parser.add_argument('--task', type=str, default='data/tasks/detect_xss_simple_prompt.txt', help='input task')\n",
    "    parser.add_argument('--template', type=str, default='data/templates/complete_function.yaml', help='template for the prompt')\n",
    "    parser.add_argument('--prompt_parameters', type=str, default='data/prompt_parameters/empty.yaml', help='parameters to format the prompt template')\n",
    "    parser.add_argument('--generation_mode', type=str, default='one_shot', help='Generation mode: one_shot, few_shot, rag or react')\n",
    "\n",
    "    #output\n",
    "    parser.add_argument('--experiments_folder', type=str, default='experiments', help='experiments folder')\n",
    "    parser.add_argument('--experiments', type=int, default=25, help= 'number of experiments to run')\n",
    "    parser.add_argument('--parameters_file_name', type=str, default='parameters.json', help='name of the parameters file')\n",
    "\n",
    "    #hf paramerters \n",
    "    parser.add_argument('--hf_max_new_tokens', type=int, default=400, help='max new tokens for hf model')\n",
    "    parser.add_argument('--hf_load_in_4bit', type=bool, default=True, help='load in 4 bit for hf model (qlora quantization)')\n",
    "\n",
    "    #reproducibility\n",
    "    parser.add_argument('--seed', type=int, default=None, help='seed for reproducibility')\n",
    "\n",
    "    #few shot parameters\n",
    "    parser.add_argument('--example_template', type=str, default='data/example_templates/detect_xss_simple', help='template for the examples')\n",
    "    parser.add_argument('--examples_per_class', type=int, default=2, help='number of examples for each class')\n",
    "    parser.add_argument('--examples_file', type=str, default='data/train.csv', help='file containing the examples')\n",
    "    parser.add_argument('--examples_payload_column', type=str, default='Payloads', help='column containing the payloads')\n",
    "    parser.add_argument('--examples_label_column', type=str, default='Class', help='column containing the labels')\n",
    "    parser.add_argument('--example_positive_label', type=str, default='Malicious', help='Label for positive examples')\n",
    "    parser.add_argument('--example_negative_label', type=str, default='Benign', help='Label for negative examples')\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#evaluation parameters\n",
    "'''\n",
    "    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\n",
    "    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\n",
    "    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\n",
    "\n",
    "    #evaluation parameters\n",
    "    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\n",
    "    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\n",
    "    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\n",
    "    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"src/generation_test_pipeline.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model_name\" : \"gpt-4-1106-preview \", # gpt-4-1106-preview  gpt-3.5-turbo-0613\n",
    "    \"temperature\" : 1.0,\n",
    "    \"task\" : \"data/tasks/detect_xss_simple_prompt.txt\",\n",
    "    \"template\" : \"data/templates/complete_function_readable.yaml\",\n",
    "    \"prompt_parameters\" : \"data/prompt_parameters/empty.yaml\",\n",
    "    \"generation_mode\" : \"few_shot\",\n",
    "    \"experiments_folder\" : \"experiments\",\n",
    "    \"experiments\" : 60,\n",
    "    \"parameters_file_name\" : \"parameters.json\",\n",
    "    \"hf_max_new_tokens\" : 400,\n",
    "    \"hf_load_in_4bit\" : True,\n",
    "    \"seed\" : 156,\n",
    "    \"example_template\" : \"data/example_templates/detect_xss_simple_prompt.txt\",\n",
    "    \"examples_per_class\" : 10,\n",
    "    \"examples_file\" : \"data/train.csv\",\n",
    "    \"examples_payload_column\" : \"Payloads\",\n",
    "    \"examples_label_column\" : \"Class\",\n",
    "    \"example_positive_label\" : \"Malicious\",\n",
    "    \"example_negative_label\" : \"Benign\",\n",
    "    \n",
    "\n",
    "\n",
    "    \"run\" : None,\n",
    "    \"data\" : \"data/test.csv\",\n",
    "    \"function_name\" : \"detect_xss\",\n",
    "    \"isolated_execution\" : None,\n",
    "    \"summarize_results\" : True,\n",
    "    \"result_file_name\" : \"results.json\",\n",
    "    \"create_confusion_matrix\" : True\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/generation_test_pipeline.py --model_name gpt-4-1106-preview  --temperature 1.0 --task data/tasks/detect_xss_simple_prompt.txt --template data/templates/complete_function_readable.yaml --prompt_parameters data/prompt_parameters/empty.yaml --generation_mode few_shot --experiments_folder experiments --experiments 60 --parameters_file_name parameters.json --hf_max_new_tokens 400 --hf_load_in_4bit True --seed 156 --example_template data/example_templates/detect_xss_simple_prompt.txt --examples_per_class 10 --examples_file data/train.csv --examples_payload_column Payloads --examples_label_column Class --example_positive_label Malicious --example_negative_label Benign --data data/test.csv --function_name detect_xss --summarize_results True --result_file_name results.json --create_confusion_matrix True \n"
     ]
    }
   ],
   "source": [
    "command = f\"python {script} \"\n",
    "for k,v in params.items():\n",
    "    if v is not None:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
