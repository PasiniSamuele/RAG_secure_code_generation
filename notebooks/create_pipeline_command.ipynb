{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\\n    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\\n    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\\n\\n    #evaluation parameters\\n    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\\n    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\\n    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\\n    parser.add_argument('--execution_dir', type=str, default='tmp', help='temporary directory for the execution of the generated code')\\n    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\\n\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generation parameters\n",
    "'''\n",
    "    parser.add_argument('--model_name', type=str, default='gpt-3.5-turbo', help='name of the model')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help='model temperature')\n",
    "\n",
    "    #task parameters\n",
    "    parser.add_argument('--task', type=str, default='data/tasks/detect_xss_simple_prompt.txt', help='input task')\n",
    "    parser.add_argument('--template', type=str, default='data/templates/complete_function.yaml', help='template for the prompt')\n",
    "    parser.add_argument('--prompt_parameters', type=str, default='data/prompt_parameters/empty.yaml', help='parameters to format the prompt template')\n",
    "    parser.add_argument('--generation_mode', type=str, default='one_shot', help='Generation mode: one_shot, few_shot, rag or react')\n",
    "\n",
    "    #output\n",
    "    parser.add_argument('--experiments_folder', type=str, default='experiments', help='experiments folder')\n",
    "    parser.add_argument('--experiments', type=int, default=25, help= 'number of experiments to run')\n",
    "\n",
    "    #hf paramerters \n",
    "    parser.add_argument('--hf_max_new_tokens', type=int, default=400, help='max new tokens for hf model')\n",
    "    parser.add_argument('--hf_load_in_4bit', type=bool, default=True, help='load in 4 bit for hf model (qlora quantization)')\n",
    "\n",
    "'''\n",
    "\n",
    "#evaluation parameters\n",
    "'''\n",
    "    parser.add_argument('--run', type=str, default=None, help='Run to be evaluated, if it is None, the last run given model parameters will be evaluated')\n",
    "    parser.add_argument('--data', type=str, default='data/test.csv', help='test dataset')\n",
    "    parser.add_argument('--function_name', type=str, default='detect_xss', help='name of the generated function to be executed for evaluation')\n",
    "\n",
    "    #evaluation parameters\n",
    "    parser.add_argument('--isolated_execution', type=bool, default=False, help='if true, the evaluation will be executed in a separate docker environment')\n",
    "    parser.add_argument('--summarize_results', type=bool, default=True, help='if true, the results for every experiment in the run will be summarized in a file')\n",
    "    parser.add_argument('--result_file_name', type=str, default='results.json', help='name of the results file')\n",
    "    parser.add_argument('--execution_dir', type=str, default='tmp', help='temporary directory for the execution of the generated code')\n",
    "    parser.add_argument('--create_confusion_matrix', type=bool, default=True, help='if true, for every experiment it generates a confusion matrix')\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"src/generation_test_pipeline.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model_name\" : \"codellama/CodeLlama-7b-Instruct-hf \", # gpt-4-1106-preview  gpt-3.5-turbo\n",
    "    \"temperature\" : 1.0,\n",
    "    \"task\" : \"data/tasks/detect_xss_simple_prompt.txt\",\n",
    "    \"template\" : \"data/templates/complete_function_readable.yaml\",\n",
    "    \"prompt_parameters\" : \"data/prompt_parameters/empty.yaml\",\n",
    "    \"generation_mode\" : \"one_shot\",\n",
    "    \"experiments_folder\" : \"experiments\",\n",
    "    \"experiments\" : 60,\n",
    "    \"hf_max_new_tokens\" : 400,\n",
    "    \"hf_load_in_4bit\" : True,\n",
    "    \"run\" : None,\n",
    "    \"data\" : \"data/test.csv\",\n",
    "    \"function_name\" : \"detect_xss\",\n",
    "    \"isolated_execution\" : None,\n",
    "    \"summarize_results\" : True,\n",
    "    \"result_file_name\" : \"results.json\",\n",
    "    \"execution_dir\" : \"tmp\",\n",
    "    \"create_confusion_matrix\" : True\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python src/generation_test_pipeline.py --model_name codellama/CodeLlama-7b-Instruct-hf  --temperature 1.0 --task data/tasks/detect_xss_simple_prompt.txt --template data/templates/complete_function_readable.yaml --prompt_parameters data/prompt_parameters/empty.yaml --generation_mode one_shot --experiments_folder experiments --experiments 60 --hf_max_new_tokens 400 --hf_load_in_4bit True --data data/test.csv --function_name detect_xss --summarize_results True --result_file_name results.json --execution_dir tmp --create_confusion_matrix True \n"
     ]
    }
   ],
   "source": [
    "command = f\"python {script} \"\n",
    "for k,v in params.items():\n",
    "    if v is not None:\n",
    "        command += f\"--{k} {v} \"\n",
    "\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
