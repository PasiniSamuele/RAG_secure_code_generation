{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig,CodeGenTokenizer,CodeGenConfig, CodeGenForCausalLM,CodeLlamaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "dotenv_values = dotenv_values()\n",
    "hf_key = dotenv_values['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id = 'Salesforce/codegen-6B-mono', \n",
    "                     model_kwargs = {\n",
    "                         \"temperature\" : 1,\n",
    "                         #\"max_length\" : 500,\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''def sum_two_numbers(num1 : int, num2 : int)->int:\n",
    "    \"\"\"Given two numbers, return the sum of them.\"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def sum_two_numbers(num1 : int, num2 : int)->int:\\n    \"\"\"Given two numbers, return the sum of them.\"\"\"\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    return num1+num2\\n\\ndef add_numbers'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(template, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 589/589 [00:00<00:00, 1.87MB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 31.4k/31.4k [00:00<00:00, 39.1MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 9.95G/9.95G [01:33<00:00, 107MB/s] \n",
      "model-00002-of-00003.safetensors: 100%|██████████| 9.90G/9.90G [01:33<00:00, 106MB/s]\n",
      "Downloading shards:  67%|██████▋   | 2/3 [03:06<01:33, 93.31s/it]/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 6178.96 MB. The target location /root/.cache/huggingface/hub only has 3010.28 MB free disk space.\n",
      "  warnings.warn(\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 6178.96 MB. The target location /root/.cache/huggingface/hub/models--codellama--CodeLlama-13b-Python-hf/blobs only has 3010.28 MB free disk space.\n",
      "  warnings.warn(\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 6.18G/6.18G [01:00<00:00, 102MB/s] \n",
      "Downloading shards: 100%|██████████| 3/3 [04:07<00:00, 82.42s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location /root/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location /root/.cache/huggingface/hub/models--codellama--CodeLlama-13b-Python-hf/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 555kB/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"codellama/CodeLlama-34b-Python-hf\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#configuration = CodeGenConfig(token = hf_key, trust_remote_code = True)\n",
    "\n",
    "# Initializing a model (with random weights) from the configuration\n",
    "#model = CodeGenForCausalLM(configuration).to(device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,trust_remote_code=True, load_in_4bit = True,token = hf_key, device_map = \"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 749/749 [00:00<00:00, 3.40MB/s]\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.50 MB. The target location /root/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.50 MB. The target location /root/.cache/huggingface/hub/models--codellama--CodeLlama-13b-Python-hf/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 20.4MB/s]\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 1.84 MB. The target location /root/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/workspaces/RAG_secure_code_generation/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:992: UserWarning: Not enough free disk space to download the file. The expected file size is: 1.84 MB. The target location /root/.cache/huggingface/hub/models--codellama--CodeLlama-13b-Python-hf/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 4.10MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 411/411 [00:00<00:00, 1.07MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code = True, token = hf_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Please complete this function\n",
    "def detect_xss(http_get_request: str) -> bool: \\n\n",
    "\"\"\" Check if in the given http_get_request there is an XSS exploit. \\n\n",
    "    Consider also the possible evansions that an attacker can perform. \\n\n",
    "\"\"\" \\n\n",
    "'''\n",
    "\n",
    "# payload = http_get_request.split('?')[1]\n",
    "# parameters = list(payload.split('&'))\n",
    "# couples_dict = dict(map(lambda x: x.split('='), parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "completion = model.generate(inputs, \n",
    "                            max_new_tokens = 500,\n",
    "                    do_sample =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> \n",
      "Please complete this function\n",
      "def detect_xss(http_get_request: str) -> bool: \n",
      "\n",
      "\"\"\" Check if in the given http_get_request there is an XSS exploit. \n",
      "\n",
      "    Consider also the possible evansions that an attacker can perform. \n",
      "\n",
      "\"\"\" \n",
      "\n",
      "# Please enter you code here\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "#,truncate_before_pattern=[r\"\\n\\n^#\", \"^'''\", \"\\n\\n\\n\"]\n",
    "output = tokenizer.decode(completion[0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4299,  2160,    62, 11545,    62,    77, 17024,     7, 22510,    16,\n",
       "          1058,   493,    11,   997,    17,  1058,   493,     8,  3784,   600,\n",
       "            25,   198, 50284, 37811, 15056,   734,  3146,    11,  1441,   262,\n",
       "          2160,   286,   606,   526, 15931,   198, 50284,  7783,   997,    16,\n",
       "          1343,   997,    17,   198,   198,  4299, 29162,    62, 11545,    62,\n",
       "            77, 17024,     7, 22510,    16,  1058,   493,    11,   997,    17,\n",
       "          1058,   493,     8,  3784,   600,    25,   198, 50284, 37811, 15056,\n",
       "           734,  3146,    11,  1441,   262,  1720,   286,   606,   526, 15931,\n",
       "           198, 50284,  7783,   997,    16,  1635,   997,    17,   198,   198,\n",
       "          4299, 14083,    62, 11545,    62,    77, 17024,     7, 22510,    16,\n",
       "          1058,   493,    11,   997,    17,  1058,   493,     8,  3784,   600,\n",
       "            25,   198, 50284, 37811, 15056,   734,  3146,    11,  1441,   262,\n",
       "         23611,  1153,   286,   606,   526, 15931,   198, 50284,  7783,   997,\n",
       "            16,  1220,   997,    17,   198,   198,  4299, 34128,    62, 11545,\n",
       "            62,    77, 17024,     7, 22510,    16,  1058,   493,    11,   997,\n",
       "            17,  1058,   493,     8,  3784,   600,    25,   198, 50284, 37811,\n",
       "         15056,   734,  3146,    11,  1441,   262,  3580,   286,   606,   526,\n",
       "         15931,   198, 50284,  7783,   997,    16,   532,   997,    17,   198,\n",
       "           198,  4299,   751,    62, 11545,    62,    77, 17024,     7, 22510,\n",
       "            16,  1058,   493,    11,   997,    17,  1058,   493,     8,  3784,\n",
       "           600,    25,   198, 50284, 37811, 15056,   734,  3146,    11,  1441,\n",
       "           262,  3090,   286,   606,   526, 15931,   198, 50284,  7783,   997,\n",
       "            16,  1343,   997,    17,   198,   198,  4299, 34128,    62, 11545,\n",
       "            62,    77, 17024,     7, 22510,    16]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|endoftext|>',\n",
       "  '<fim-prefix>',\n",
       "  '<fim-middle>',\n",
       "  '<fim-suffix>',\n",
       "  '<fim-pad>']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"<|endoftext|>\" in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
